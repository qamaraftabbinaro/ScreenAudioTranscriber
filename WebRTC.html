<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Screen Audio Recorder</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
</head>
<body class="bg-light">
    <div class="container py-5">
        <h1 class="mb-4">Screen Audio Recorder</h1>
        
        <!-- Controls -->
        <div class="mb-4">
            <button id="startScreen" class="btn btn-primary me-2">Start Screen Share</button>
            <button id="startRecord" class="btn btn-success me-2" disabled>Start Recording</button>
            <button id="stopRecord" class="btn btn-danger" disabled>Stop Recording</button>
        </div>

        <!-- Status -->
        <div id="status" class="alert alert-info" style="display: none;"></div>

        <!-- Audio Player -->
        <div class="mt-4">
            <h4>Recorded Audio</h4>
            <audio id="audioPlayback" controls class="w-100"></audio>
        </div>

        <div id="audoiToSpeech" class="alert alert-success">

        </divb>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    
    <script>
        const startScreen = document.getElementById('startScreen');
        const startRecord = document.getElementById('startRecord');
        const stopRecord = document.getElementById('stopRecord');
        const audioPlayback = document.getElementById('audioPlayback');
        const status = document.getElementById('status');
        
        let mediaStream;
        let mediaRecorder;
        let recordedChunks = [];

        // Start screen sharing with system audio
        startScreen.addEventListener('click', async () => {
            try {
                mediaStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true,
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false,
                        suppressLocalAudioPlayback: false
                    }
                });

                const audioTracks = mediaStream.getAudioTracks();
                if (audioTracks.length === 0) {
                    alert('Please check "Share audio" when selecting what to share!');
                    mediaStream.getTracks().forEach(track => track.stop());
                    return;
                }

                startRecord.disabled = false;
                startScreen.disabled = true;
                status.style.display = 'none';
            } catch (err) {
                console.error('Error accessing media devices:', err);
            }
        });

        // Start recording
        startRecord.addEventListener('click', () => {
            startRecording();
            setTimeout(() => {
                CallEvery3Seconds(); 
            }, 1000);
        });

        // Stop recording
        stopRecord.addEventListener('click', () => {
            mediaRecorder.stop();
            startRecord.disabled = false;
            stopRecord.disabled = true;
            startScreen.disabled = false;
        });

        // Function to send audio to .NET Core backend
        async function sendAudioToServer(blob) {
            const formData = new FormData();
            formData.append('audioFile', blob, `recording-${Date.now()}.webm`);
            startRecording();
            const response = await fetch('http://103.192.152.69:5000/transcribe', {
                method: 'POST',
                body: formData,
               });

            if (!response.ok) {
            }

            return response.json();
        }

        function CallEvery3Seconds()
        {   setInterval(() => {
             console.log('stop');
                mediaRecorder.stop();
            }, 3000);
        } 

        function startRecording()
        {
            console.log('start');
            recordedChunks = [];
            // Create audio-only stream
            const audioStream = new MediaStream(mediaStream.getAudioTracks());
            
            mediaRecorder = new MediaRecorder(audioStream, {
                mimeType: 'audio/webm; codecs=opus'
            });

            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) recordedChunks.push(e.data);
            };
            
            mediaRecorder.onstop = async () => {
                console.log('stop');
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                recordedChunks= [];
                // Playback
                audioPlayback.src = URL.createObjectURL(blob);
                //audioPlayback.play();

                // Send to server
                status.textContent = 'Uploading audio...';
                status.style.display = 'block';
                
                try {
                    var result = await sendAudioToServer(blob);
                    document.getElementById("audoiToSpeech").appendChild(document.createTextNode(result.message));
                    status.textContent = 'Audio uploaded successfully!';
                } catch (error) {
                    console.error('Upload failed:', error);
                    status.textContent = 'Upload failed! Check console for details.';
                }
            };

            mediaRecorder.start();
            startRecord.disabled = true;
            stopRecord.disabled = false;
            status.textContent = 'Recording...';
            status.style.display = 'block';
        } 
    </script>
</body>
</html>